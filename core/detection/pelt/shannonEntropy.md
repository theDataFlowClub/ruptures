# Entrop√≠a de Shannon como funci√≥n de costo en PELT

**Objetivo:**
Integrar la **entrop√≠a binaria de Shannon** como funci√≥n de costo dentro del algoritmo PELT, para detectar puntos de cambio donde cambia el patr√≥n de incertidumbre/informaci√≥n en una se√±al de 0s y 1s.

---

### üß† Fundamento matem√°tico

La entrop√≠a de Shannon mide la cantidad de incertidumbre en una distribuci√≥n de probabilidad discreta. Para una variable binaria $X \in \{0,1\}$ con probabilidades $p_0, p_1$, su entrop√≠a es:

$$
H(X) = -p_0 \log_2 p_0 - p_1 \log_2 p_1
$$

Aplicado a un **segmento binario $[s, t)$** de una se√±al:

* Sean:

  * $n = t - s$: longitud del segmento
  * $n_0$: n√∫mero de ceros en el segmento
  * $n_1 = n - n_0$: n√∫mero de unos
* Entonces:

  $$
  p_0 = \frac{n_0}{n}, \quad p_1 = \frac{n_1}{n}
  $$
* La **entrop√≠a del segmento** es:

  $$
  H(s, t) = -p_0 \log_2 p_0 - p_1 \log_2 p_1
  $$

Y la **funci√≥n de costo** es:

$$
\text{Cost}_{[s,t)} = n \cdot H(s, t) = -n \cdot \left( \frac{n_0}{n} \log_2 \frac{n_0}{n} + \frac{n_1}{n} \log_2 \frac{n_1}{n} \right)
$$

Que se simplifica a:

$$
\text{Cost}_{[s,t)} = -n_0 \log_2 \left( \frac{n_0}{n} \right) - n_1 \log_2 \left( \frac{n_1}{n} \right)
$$

Esto tiene una interpretaci√≥n clara:

* El costo es **m√≠nimo (0)** cuando el segmento es puro (todo 0s o todo 1s).
* El costo es **m√°ximo** cuando el segmento es uniforme (mitad 0s, mitad 1s ‚Üí entrop√≠a m√°xima de 1 bit).

---

### üîé Propiedades √∫tiles

* Es una **funci√≥n convexa** en $p$.
* Refleja la **incertidumbre estructural** del segmento.
* Es **sim√©trica**: no importa si cambias 0s por 1s.
* **Invariante a rotaci√≥n** en se√±ales binarias (posici√≥n no importa, solo proporci√≥n).

---

### üì¶ Aplicaci√≥n en PELT

* Dentro del marco de PELT, esta funci√≥n se usa como `Cost.Error(start, end)`.
* No requiere estad√≠sticas acumuladas sobre valores, sino **conteo acumulado de 0s y 1s**.

---

### ‚öôÔ∏è Posible optimizaci√≥n computacional

Para cada √≠ndice $i \in [0, n]$, se pueden precomputar:

```go
prefixCount0[i] = n√∫mero de ceros en y[0:i]
prefixCount1[i] = i - prefixCount0[i]
```

Entonces para cualquier $[s, t)$:

```go
n0 = prefixCount0[t] - prefixCount0[s]
n1 = (t - s) - n0
```

Y luego:

```go
p0 = float64(n0) / float64(t - s)
p1 = float64(n1) / float64(t - s)
cost = -float64(n0)*math.Log2(p0) - float64(n1)*math.Log2(p1)
```

Con protecciones para evitar `log2(0)`:

```go
if p0 > 0 { ... } else { 0.0 }
```

---

### ‚úÖ Ventajas

* Interpretable: muestra d√≥nde cambia la estructura informativa del stream binario.
* Eficiente: usando prefix sums, se puede calcular en $O(1)$ por segmento.
* Robusto a ruido binario, √∫til para secuencias de eventos o logs.

---

### ‚ö†Ô∏è Consideraciones

* Requiere que la se√±al est√© codificada como binaria expl√≠cita (`0` o `1`).
* La m√©trica de entrop√≠a **no es diferenciable**, pero esto no afecta a PELT (que es discreto).
* Cuando $n_0 = 0$ o $n_1 = 0$, el t√©rmino correspondiente debe omitirse para evitar `log2(0)`.

---

### üìå Conclusi√≥n

La funci√≥n de entrop√≠a binaria de Shannon puede usarse como una funci√≥n de costo v√°lida dentro del marco de PELT, para detectar cambios en patrones binarios. La implementaci√≥n es directa usando contadores acumulativos, y puede extenderse a otros contextos discretos (multiclase, categ√≥ricos) con mayor complejidad.

---